```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE
)
library(tidyverse)
library(rstantools)
library(rstan)
library(posterior)
library(patchwork)
library(lme4)
library(rstanarm)
library(magrittr)
library(furrr)
library(kableExtra)
library(purrr)

tba <- function(dat, cap = NA){
  kable(dat,
      format = "html", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = F)%>%
         kable_classic(full_width = F, html_font = "Arial Narrow")
}
```

# Aplicación: Índice de Pobreza Multidimensional en Colombia. 

Nos centramos en la incidencia de la pobreza multidimensional descrito previamente. En este caso, requerimos $K = 9$ indicadores que se miden como privaciones: $y_{di}^{k} = 1$ si la persona tiene la privación y $y_{di}^{k} = 0$ si la persona no ha tenido la privación.

El índice requiere información para cada individuo $i = 1, \ldots, N_d$ en los dominios $d = 1, \ldots, D$, donde $N_d$ denota el tamaño de la población del dominio $d$.

La función indicadora $I(\cdot)$ es igual a 1 cuando se cumple la condición $q_{di} \ge z$. Para este estudio, utilizamos el valor de 0.4 para $z$, es decir, $I(\cdot)$ es igual a 1 cuando $q_{di} \ge 0.4$. $q_{di}$ es una cantidad ponderada que considera los $K = 9$ indicadores que conforman el índice. El valor de $q_{di}$ el dominio $d$ se calcula como:

  
$$
  q_{di} = \frac{1}{12}\sum_{k =1}^{12}y_{di}^{k} 
$$
  
 
Donde: 
  
| Categoría  | Variable          | Descripción                                                                |
|------------|-------------------|----------------------------------------------------------------------------|
| Educación  | nbi_hnolee_ee     | Al menos un mayor de 10 años no sabe leer en el hogar                      |
|            | nbi_hlogroeduc_ee | Todos los integrantes del hogar entre 18 y 64 están privados en la nbi_educ individual |
|            | nbi_heducninios   | Al menos un menor de edad no asiste o está rezagado                         |
| Vivienda   | nbi_hhacina       |                                                                             |
|            | nbi_henergia      |                                                                             |
|            | nbi_htic          |                                                                             |
| Salud      | nbi_hagua_ee      |                                                                             |
|            | nbi_hsaneamiento_ee |                                                                             |
|            | nbi_hsalud_ee     |                                                                             |
| Empleo     | nbi_hpartemp      | Al menos un individuo del hogar tiene empleo temporal según la condición y edad |
|            | nbi_hempe         | Todos los individuos ocupados del hogar cumplen ciertas condiciones de empleo |
|            | nbi_hjub          | Al menos un individuo del hogar es jubilado según edad y pensión            |



Los datos de la encuesta y el censo han sido preparados previamente, la información sobre la cual realizaremos la predicción corresponde a Colombia en el 2019 

```{r, eval=TRUE}
encuesta_ipm <-
  readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Encuestas/encuesta_nbi.rds")
statelevel_predictors_df <-
  readRDS("Modelo_bayes_HxA_Hogar/COL/Data/statelevel_predictors_df_dam2.rds") 

byAgrega <- c("dam",
              "dam2",
              "area",
              "sexo",
              "etnia",
              "anoest",
              "edad")
```

Agregando la información para los municipios de Colombia para los indicadores que conformarán el IPM

```{r, eval=TRUE}
names_ipm <- c(
  "nbi_hnolee_ee" ,
  "nbi_hlogroeduc_ee" ,
  "nbi_heducninios" ,
  "nbi_hhacina" ,
  "nbi_henergia" ,
  "nbi_htic" ,
  "nbi_hagua_ee" ,
  "nbi_hsaneamiento_ee" ,
  "nbi_hsalud_ee" ,
  "nbi_hpartemp" ,
  "nbi_hempe" ,
  "nbi_hjub"
)  

encuesta_df <- map(setNames(names_ipm,names_ipm),
                   function(y){
                     encuesta_ipm$temp <- as.numeric(encuesta_ipm[[y]])
                     encuesta_ipm %>% 
                       group_by_at(all_of(byAgrega)) %>%
                       summarise(n = n(),
                                 yno = sum(temp),
                                 ysi = n - yno, .groups = "drop") %>% 
                       inner_join(statelevel_predictors_df,
                                  by = c("dam","dam2"))
                   })
```

La base resultante quedan de la siguiente forma:

```{r, echo=FALSE}
tba(encuesta_df[[names_ipm[1]]] %>% arrange(desc(n)) %>% head(), 
    cap = names_ipm[1])
```

```{r, echo=FALSE}
tba(encuesta_df[[names_ipm[2]]] %>% arrange(desc(n)) %>% head(), 
    cap = names_ipm[2])

```

## Definiendo de los modelos en Stan.

Para cada dimensión que compone el IPM se ajusta un modelo mixtos logit Bernoulli estimando mediante técnicas bayesiana. En este código se incluye el uso de la función `future_map` que permite procesar en paralelo cada modelo O puede compilar cada por separado, en nuestro caso se proceso cada modelo por separado.    

```{r, eval = FALSE}
library(furrr)
names_cov <-  statelevel_predictors_df %>%
  dplyr::select(-dam,-dam2) %>%
  names()
names_cov <- c("sexo","area",names_cov[16:19])
efec_aleat <-
  paste0("(1|",
         c("dam", "etnia"),
         ")",
         collapse = "+")

formula_mod <-
  formula(paste(
    " cbind(yno, ysi) ~",
    efec_aleat,
    "+",
    paste0(names_cov,
           collapse = " + ")
  ))

formula_mod
```

Ejecutando los modelos 

```{r, eval = FALSE}
run_bayesian_model <- function(variable, data) {
  fit <- stan_glmer(
    formula = formula_mod,
    family = binomial(link = "logit"),
    data = data[[variable]],
    cores = 4,
    chains = 4,
    iter = 500,
    open_progress = TRUE
  )
  
  saveRDS(fit, file = paste0("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_", 
                             variable, ".rds"))
}

for (variable in nbi_hogar) {
  run_bayesian_model(variable, encuesta_df)
}

```

### Prueba del $\hat{R}$

En modelos Bayesianos, la prueba **Rhat** es utilizada para evaluar la convergencia de las cadenas MCMC. La idea es verificar si múltiples cadenas MCMC han convergido al mismo valor de la distribución posterior.

#### Fórmula de Rhat

La fórmula para calcular Rhat es la siguiente:

$$ \hat{R} = \sqrt{\frac{\text{Varianza entre cadenas}}{\text{Varianza dentro de cadenas}}} $$

Donde:
- Varianza entre cadenas: Varianza de los valores de un parámetro entre todas las cadenas MCMC.
- Varianza dentro de cadenas: Varianza de los valores de un parámetro dentro de cada cadena MCMC.

#### Interpretación de Rhat

- Si $\hat{R}$ es cercano a 1, indica buena convergencia de las cadenas.
- Valores mayores a 1.1 pueden indicar problemas de convergencia y la necesidad de revisar las cadenas y el modelo.

```{r}
library(rstantools)
library(bayesplot)
for(ii in 1:12){
modelo_rds <- paste0("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_", names_ipm[ii], ".rds")
s <- rhat(readRDS(modelo_rds))
s <- mcmc_rhat(s) + ggtitle(names_ipm[ii]) 
print(s)
}
```


Terminado la compilación de los modelos después de realizar validaciones sobre esto, pasamos hacer las predicciones en el censo. 

## Proceso para la predicción $\pi_{di}^{kl}$

Los modelos fueron compilados de manera separada, por tanto, disponemos de un objeto `.rds` por cada dimensión del IPM 

```{r, eval=FALSE}
crear_epred_mat_dummy <- function(variable, newdata) {
  # Paso 1: Cargar el modelo
  modelo_rds <- paste0("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_", variable, ".rds")
  ruta_guardado <- paste0("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_", variable, ".rds")
  fit <- readRDS(file = modelo_rds)
  
  # Paso 2: Generar epred_mat
  epred_mat <- posterior_epred(
    fit,
    newdata = newdata,
    type = "response",
    allow.new.levels = TRUE
  )
  
  # Paso 3: Generar epred_mat_dummy
  epred_mat_dummy <- rbinom(n = nrow(epred_mat) * ncol(epred_mat), 1, epred_mat)
  epred_mat_dummy <- matrix(epred_mat_dummy, nrow = nrow(epred_mat), 
                            ncol = ncol(epred_mat))
  
  # Guardar epred_mat_dummy como un archivo .rds
  saveRDS(epred_mat_dummy, file = ruta_guardado)
  cat(ruta_guardado, "\n")

}


```

Note que la función se encarga de leer los modelos que fueron estimados previamente, luego se obtienen las $L$ predicciones de $\pi_{di}^{kl}$,


```{r, eval=FALSE}
epred_mat <- posterior_epred(
  fit_agua,
  newdata = newdata,
  type = "response",
  allow.new.levels = TRUE
)
```

Los resultados anteriores se deben procesarse para obtener los hard estimates, es decir, términos de carencia (1) y  no carencia (0) para la $k-esima$ carencias. Lo que se realiza con el código



```{r, eval=FALSE}
 epred_mat_dummy <- rbinom(n = nrow(epred_mat) * ncol(epred_mat), 1, epred_mat)
  epred_mat_dummy <- matrix(epred_mat_dummy, nrow = nrow(epred_mat), 
                            ncol = ncol(epred_mat))
```


Ahora, debemos leer la información del censo  y crear los **post-estrato **

```{r, eval=TRUE}
censo_ipm <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Censo/censo_COL.rds") %>%
  rename(dam = depto, dam2 = mpio) %>%
  group_by(dam,   dam2,  area,  sexo,  edad,  etnia, anoest) %>%
  summarise(n = sum(n), .groups = "drop")

statelevel_predictors_df <-
  readRDS("Modelo_bayes_HxA_Hogar/COL/Data/statelevel_predictors_df_dam2.rds") 
```

Para realizar la predicción en el censo debemos incluir la información auxiliar 


```{r, eval=TRUE}
poststrat_df <- left_join(censo_ipm, statelevel_predictors_df,
                          by = c("dam", "dam2")) 
```

Ahora, para obtener los  **hard estimates** usamos el siguinte código 


```{r, eval=FALSE}
for(ii in 1:12){
crear_epred_mat_dummy(names_ipm[ii],poststrat_df) # OK  
}
```



## Calculando $q_{di}^{l}$, $I\left( q_{di}^{l} \ge z \right)$ y $c_{di}^{l}\left(z\right)$

Dado que los hard estimates fueron organizados en matrices, el calculo de $q^{l}_{id}$ es una simple operación matricial la cual se muestra a continuación 
```{r, eval=FALSE}
epred_mat_dummy_hnolee <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hnolee_ee.rds")
epred_mat_dummy_hlogroeduc <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hlogroeduc_ee.rds")
epred_mat_dummy_heducninios <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_heducninios.rds")
epred_mat_dummy_hhacina <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hhacina.rds")
epred_mat_dummy_henergia <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_henergia.rds")
epred_mat_dummy_htic <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_htic.rds")
epred_mat_dummy_hagua <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hagua_ee.rds")
epred_mat_dummy_hsaneamiento <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hsaneamiento_ee.rds")
epred_mat_dummy_hsalud <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hsalud_ee.rds")
epred_mat_dummy_hpartemp <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hpartemp.rds")
epred_mat_dummy_hempe <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hempe.rds")
epred_mat_dummy_hjub <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hjub.rds")
```

```{r, eval=FALSE}
chain_q  <-
(1/12)*(epred_mat_dummy_hnolee +
epred_mat_dummy_hlogroeduc +
epred_mat_dummy_heducninios +
epred_mat_dummy_hhacina +
epred_mat_dummy_henergia +
epred_mat_dummy_htic +
epred_mat_dummy_hagua +
epred_mat_dummy_hsaneamiento +
epred_mat_dummy_hsalud +
epred_mat_dummy_hpartemp +
epred_mat_dummy_hempe +
epred_mat_dummy_hjub )
```

```{r,echo=FALSE}
chain_q <- readRDS("Modelo_bayes_HxA_Hogar/COL/Data/Modelo/chain_q.rds")

```

Ahora, es posible tener el calculo de $I\left( q_{di}^{l} \ge z \right)$, tomando como umbral $z=0.4$. 

```{r, eval=TRUE}
chain_Ind <- chain_q
chain_Ind[chain_Ind < 0.4] <- 0
chain_Ind[chain_Ind != 0] <- 1
```

seguidamente calculamos $c_{di}^{l}\left(z\right)$ 

```{r}
chain_ci <- matrix(0,nrow = nrow(chain_q), ncol = ncol(chain_q))
chain_ci[chain_Ind == 1] <- chain_q[chain_Ind == 1]

```


```{r, eval=TRUE}
datos<-data.frame(t(chain_q[1:5,1:10]), t(chain_Ind[1:5,1:10]), t(chain_ci[1:5,1:10]),
                  N = censo_ipm$n[1:10] )
colnames(datos) <- c(paste0("q",1:5), paste0("Ind",1:5),paste0("c",1:5),"N")
tba(datos, "Cadenas obtenidas")
```

## Estimación de $H$, $A$ e $IPM$
Para este proceso debemos realizar sumas ponderadas, dado que cada registro de la base de datos representa  un grupo de observaciones con las mismas características.  

```{r}
numIPM <- t(chain_ci) %>%
  as.data.frame() %>%
  mutate_all(~ . * censo_ipm$n) %>%
  as.matrix()

chain_N <- t(chain_Ind) %>%
  as.data.frame() %>%
  mutate_all(~ . * censo_ipm$n) %>%
  as.matrix()


IPM_l <- colSums(numIPM)/sum(censo_ipm$n)
Nz_l <- colSums(chain_N)
H_l <- Nz_l/sum(censo_ipm$n)
A_l <- colSums(numIPM)/Nz_l
```

```{r, echo=FALSE}
datos_chain <- data.frame(IPM_l,Nz_l,H_l,A_l,HA_l = H_l*A_l) %>% 
  slice(1:10)
rownames(datos_chain) <- paste0("l = ", 1:10)
tba(datos_chain, "l-iteraciones")
```


Por último se realiza las estimaciones puntuales y varianza para $H$, $A$ y $IPM$, esto es:  

```{r}
estimacion <- data.frame(H = mean(H_l),
           H_sd = sd(H_l),
           A = mean(A_l),
           A_sd = sd(A_l),
           IPM = mean(IPM_l),
           IPM_sd = sd(IPM_l))
```


```{r, echo=FALSE}
tba(estimacion, "Estimaciones Nacionales")
```
## Estimaciones desagregadas del IPM

Para realizar las estimaciones desagregadas se desarrollo una función que facilita el calculo, la estructura general el proceso es repetir el proceso anterior por subgrupos, por ejemplo, departamento (*dam*)

```{r}
source("Modelo_bayes_HxA_Hogar/0funciones/Estimar_ipm.R")
ipm_dam <- estime_IPM(
  poststrat = censo_ipm,
  chain_ci = chain_ci,
  chain_ind = chain_ind,
  byMap = "dam"
) %>% data.frame()
```


```{r, echo=FALSE}
tba(ipm_dam, "Estimaciones por departamento")
```

Otra estimación desagregada que es posible obtener es la combinación por departamento y sexo, para ellos se usa la sintaxis. 


```{r}
ipm_dam_sexo <- estime_IPM(
  poststrat = censo_ipm,
  chain_ci = chain_ci,
  chain_ind = chain_ind,
  byMap = c("dam", "sexo")
) %>% data.frame()
```


```{r,eval=FALSE, echo=FALSE}
ipm_mpio <- estime_IPM(
  poststrat = censo_ipm,
  chain_ci = chain_ci,
  chain_ind = chain_ind,
  byMap = "dam2"
) %>% data.frame()

saveRDS(ipm_mpio,"Modelo_bayes_HxA/COL/Data/estimado_ipm.rds")
```


```{r, echo=FALSE}
tba(ipm_dam_sexo, "Estimaciones por departamento y sexo")
```

## Estimaciones por dimension del IPM 
Dado que el Índice de Pobreza Multidimensional (IPM) está compuesto por diversas dimensiones, resulta fundamental analizar cada una de estas dimensiones de manera individual. Esto permite comprender la naturaleza compleja y multifacética de la pobreza, lo cual a su vez posibilita diseñar estrategias de reducción efectivas. Esta aproximación garantiza una toma de decisiones fundamentada, la distribución eficiente de recursos y un impacto más profundo en la mejora de las condiciones de vida de las personas vulnerables. En este contexto, los "hard estimates" previamente obtenidos para cada dimensión resultan esenciales para obtener las estimaciones correspondientes a cada una de ellas.

El proceso de cálculo se basa en una media ponderada y se aplica a la dimensión de **Hacinamiento**, siguiendo una lógica similar para las demás dimensiones del IPM.
```{r, echo=FALSE}
epred_mat_hacinamiento_dummy <- readRDS("Modelo_bayes_HxA_hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hhacina.rds")
```


```{r}
n_filtered <- censo_ipm$n
epred_mat_filtered <- epred_mat_hacinamiento_dummy
mrp_estimates <- epred_mat_filtered %*% n_filtered / sum(n_filtered)
datos <- data.frame(
  estimate = mean(mrp_estimates),
  estimate_se = sd(mrp_estimates)
)
```

```{r, echo=FALSE}
tba(datos, "Estimaciones nacional para  Hacinamiento")
```

Con el objetivo de agilizar el proceso de calculo se define crea la función **agregado_dim_ipm** que hace los cálculos. La forma de uso es la siguiente. 

```{r,}
source("Modelo_bayes_HxA_Hogar/0funciones/agregado_dim_ipm.r")
datos_dam_haci <- agregado_dim_ipm(poststrat = censo_ipm,
           epredmat = epred_mat_hacinamiento_dummy,
           byMap = "dam")

```


```{r, echo=FALSE}
tba(datos_dam_haci, "Estimaciones por departamento para Hacinamiento")
```

El resultado por municipio y para todas las dimensiones se muestra en la siguiente tabla
```{r, echo=FALSE}
temp_estimate_mpio <- readRDS("Modelo_bayes_HxA_Hogar/COL/data/Modelo/temp_estimate_mpio.rds")

temp <- spread(temp_estimate_mpio %>% select(-estimate_se),
       key = "Indicador",value = "estimate") %>% 
  head(10)
tba(temp, cap = "Estimacion puntual por municipio y dimension")
```


```{r, echo=FALSE}
temp <- spread(temp_estimate_mpio %>% select(-estimate),
       key = "Indicador",value = "estimate_se") %>% 
  rename_if(is.numeric, .funs = function(x)paste0(x,"_se")) %>% head(10)
tba(temp, cap = "Error de estimacion por municipio y carencia")

```


