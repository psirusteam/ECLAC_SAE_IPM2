[["index.html", "Metodología bayesiana de estimación desagregada para cualquier IPM Capítulo 1 Introducción", " Metodología bayesiana de estimación desagregada para cualquier IPM Andrés Gutiérrez1, Stalyn Guerrero2 2024-04-16 Capítulo 1 Introducción El Índice de Pobreza Multidimensional (IPM) es una medida de la pobreza que toma en cuenta múltiples dimensiones de la vida humana, como la salud, la educación, el acceso a los servicios básicos y las condiciones de vida. Fue desarrollado por Sabina Alkire y James Foster en 2007, y se ha utilizado para medir la pobreza en más de 100 países. El IPM es importante porque ofrece una visión más completa de la pobreza que las medidas tradicionales de la pobreza, que se basan en el ingreso o el consumo. El IPM permite identificar a las personas que son pobres en múltiples dimensiones, y proporciona información sobre las dimensiones de la pobreza que más impactan en la vida de las personas. El IPM tiene algunas limitaciones. Una limitación es que es difícil de calcular, ya que requiere datos sobre múltiples dimensiones de la pobreza. Otra limitación es que el IPM puede ser subjetivo, ya que depende de las dimensiones que se incluyen en el índice y de los pesos que se asignan a cada dimensión. En los últimos años, se han desarrollado metodologías más recientes para el cálculo del IPM. Estas metodologías tienen en cuenta algunas de las limitaciones del IPM tradicional, y ofrecen una visión más precisa de la pobreza multidimensional. Una de las metodologías más recientes es el IPM de Alkire-Foster-Sen (Alkire, Foster y Sen, 2010). Este índice es similar al IPM tradicional, pero tiene en cuenta la desigualdad entre las personas que son pobres. El IPM de Alkire-Foster-Sen también permite identificar a las personas que son pobres en una dimensión, pero no en otras. El IPM es una herramienta importante para medir la pobreza multidimensional. Ofrece una visión más completa de la pobreza que las medidas tradicionales de la pobreza, y proporciona información sobre las dimensiones de la pobreza que más impactan en la vida de las personas. En los últimos años, se han desarrollado metodologías más recientes para el cálculo del IPM, que ofrecen una visión más precisa de la pobreza multidimensional. Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["índice-de-pobreza-multidimensional.html", "Capítulo 2 Índice de Pobreza Multidimensional", " Capítulo 2 Índice de Pobreza Multidimensional El Índice de Pobreza Multidimensional (IPM) es una medida que captura la pobreza desde múltiples dimensiones. Se calcula utilizando ponderaciones y umbrales en función de diferentes variables o indicadores que reflejan aspectos diversos de la calidad de vida. Ahora el IPM es un caso particular de la metodología de la tasa de pobreza ajustada FGT (Foster, Greer y Thorbecke, 1984) de medidas de pobreza unidimensionales. Al igual que cada medida FGT se puede ver como la media de un vector apropiado construido a partir de los datos originales y censurado usando la línea de pobreza, la tasa de pobreza ajustada es la media del vector de puntuación de privación censurado. \\[ IPM = \\frac{1}{N}\\sum_{i=1}^{N}c_i(z) \\] donde, \\(N\\) es el número de individuos u hogares en la población y \\(c_i(z)\\) es el puntaje de privación censurado de la observación \\(i\\) que esta dado como: \\[ c_{i}\\left(z\\right)=\\begin{cases} q_i &amp; \\text{si } q_i\\ge z\\\\ 0 &amp; \\text{si } q &lt; z \\end{cases} \\] con \\[ q_i = \\sum_{k=1}^{K} w_k \\cdot y_{i}^{k} \\] Donde: \\(K\\) es el número de dimensiones o indicadores de la privación. \\(w_k\\) es el ponderador asociado a la dimensión \\(k\\). \\(y_{i}^{k}\\) es una variable binaria que toma el valor \\(1\\) si el individuo \\(i\\) esta privado en la dimensión \\(k\\) y \\(0\\) en el caso contrario. \\(z\\) es el umbral para considerar a alguien con multiples privaciones. Una segunda forma de ver es en términos de índices parciales, es decir, medidas que proporcionan información básica sobre un solo aspecto de la pobreza. A continuación vemos cada uno de estos componentes: Headcount Ratio (H) Este componente mide la proporción de personas que están privadas en al menos una de las dimensiones consideradas. Matemáticamente, \\(H\\) se calcula como la proporción entre el número de personas privadas y la población total: \\[ H = \\frac{1}{N} \\sum_{i=1}^{N} I\\left( q_{i} \\ge z \\right)= \\frac{N\\left(z\\right)}{N} \\] donde \\(N\\left(z\\right) = \\sum_{i=1}^{N} I\\left( q_{i} \\ge z \\right)\\) Intensity of Deprivation (A) Este componente mide la intensidad o gravedad promedio de la privación entre aquellos que están privados. Matemáticamente, \\(A\\) se calcula como el promedio de los indicadoras \\(y_{i}^{k}\\) para aquellos hogares o personas que están privados: \\[ A=\\sum_{i=1}^{N}\\frac{c_{i}\\left(z\\right)}{N\\left(z\\right)} \\] Luego, el Índice de Pobreza Multidimensional (IPM) se expresa como: \\[ IPM = H \\times A \\] reemplazando las \\(H\\) y \\(A\\) por sus respectivas ecuaciones se tiene que: \\[ IPM=\\frac{N\\left(z\\right)}{N}\\times\\sum_{i=1}^{N}\\frac{c_{i}\\left(z\\right)}{N\\left(z\\right)}=\\frac{1}{N}\\sum_{i=1}^{N}c_{i}\\left(z\\right) \\] "],["ejemplo.html", "2.1 Ejemplo", " 2.1 Ejemplo Para ilustrar el cálculo del Índice de Pobreza Multidimensional (IPM), empleamos el conjunto de datos simulados a continuación. Consideremos un escenario con diez observaciones (\\(N = 10\\)), a las cuales se les han asignado nueve dimensiones distintas (\\(K = 9\\)). Estas dimensiones están ponderadas de acuerdo con el vector \\(w = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2)\\). # Definición de parámetros K &lt;- 9 # Número de dimensiones N &lt;- 10 # Número de personas w &lt;- c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2) # Ponderaciones para cada dimensión A continuación se realiza la simulación de la matriz de variables dicótomicas para las diez persona respondientes set.seed(1234) # Generación de datos simulados M_dummy &lt;- matrix(sample(x = c(1,0),size = N * K, replace = TRUE), nrow = N, ncol = K) # Matriz de dimensiones aleatorias colnames(M_dummy)&lt;- paste0(&quot;y&quot;,1:K) rownames(M_dummy)&lt;- paste0(&quot;P&quot;,1:N) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 0 0 1 0 0 0 0 1 P2 0 0 0 0 1 0 0 1 0 P3 0 0 0 1 0 0 1 1 1 P4 0 1 0 1 0 0 0 1 0 P5 1 0 0 1 0 1 1 0 1 P6 0 0 0 0 1 0 1 0 0 P7 1 0 1 1 1 1 0 0 1 P8 1 1 0 0 1 1 1 1 0 P9 1 0 0 0 1 0 1 0 0 P10 0 0 0 1 0 1 0 1 1 A continuación se realiza el calculo de H y A usando las ecuaciones dadas previamente. q &lt;- M_dummy %*% w # Vector q de ponderaciones por dimensiones Indicadora &lt;- ifelse(q &gt;= 0.4,1,0) c_i &lt;- ifelse(Indicadora == 1, q,0) datos &lt;- data.frame(M_dummy, q_i = q, Ind_i = Indicadora, c_i) y1 y2 y3 y4 y5 y6 y7 y8 y9 q_i Ind_i c_i P1 0 0 0 1 0 0 0 0 1 0.3 0 0.0 P2 0 0 0 0 1 0 0 1 0 0.2 0 0.0 P3 0 0 0 1 0 0 1 1 1 0.5 1 0.5 P4 0 1 0 1 0 0 0 1 0 0.3 0 0.0 P5 1 0 0 1 0 1 1 0 1 0.6 1 0.6 P6 0 0 0 0 1 0 1 0 0 0.2 0 0.0 P7 1 0 1 1 1 1 0 0 1 0.7 1 0.7 P8 1 1 0 0 1 1 1 1 0 0.6 1 0.6 P9 1 0 0 0 1 0 1 0 0 0.3 0 0.0 P10 0 0 0 1 0 1 0 1 1 0.5 1 0.5 Para obtener el \\(IPM\\) procedemos así IPM = mean(datos$c_i) Los componentes \\(H\\) y \\(A\\) los se obtienen así: Nz = sum(datos$Ind_i) H = Nz/N A = sum(datos$c_i)/Nz data.frame(A,H,HA = H*A, IPM) %&gt;% tba() A H HA IPM 0.58 0.5 0.29 0.29 "],["estimación-del-modelo-de-unidad-para-variables-binarias.html", "Capítulo 3 Estimación del modelo de unidad para variables Binarias", " Capítulo 3 Estimación del modelo de unidad para variables Binarias En muchas aplicaciones, la variable de interés en áreas pequeñas puede ser binaria, por ejemplo, \\(y_{di} = 0\\) ó \\(1\\), representando la ausencia (o no) de una característica específica. En el caso binario, la estimación objetivo en cada dominio \\(d = 1, \\dotso, D\\) puede ser la proporción \\(\\bar{Y}_d = \\pi_d = \\frac{1}{N_d} \\sum_{i=1}^{N_d} y_{di}\\) de la población que tiene esta característica, donde \\(N=\\sum_{d=1}^{D}N_d\\) y \\(\\pi_{di}\\) es la probabilidad de que una unidad específica \\(i\\) en el dominio \\(d\\) obtenga el valor 1. Aunque se han propuesto otros métodos para resultados binarios, como el modelado basado en M-cuantiles (Chambers et al., 2016), en esta aplicación seguimos el enfoque tradicional basado en modelos mixtos lineales generalizados. En este escenario, \\(\\pi_{di}\\) se modela con una función de enlace logit definida como: \\[ \\text{logit}(\\pi_{di}) = \\log \\left( \\frac{\\pi_{di}}{1 - \\pi_{di}} \\right) = \\eta_{di} = \\mathbf{x}_{di}^\\top \\mathbf{\\beta} + u_d \\] con \\(i = 1, \\ldots, N_d\\), \\(d = 1, \\ldots, D\\), \\(\\boldsymbol{\\beta}\\) un vector de parámetros de efectos fijos y \\(u_d\\) el efecto aleatorio específico del área para el dominio \\(d\\) con \\(u_d \\sim N(0, \\sigma_u^2)\\). Se asume que \\(u_d\\) son independientes y \\(y_{di} | u_d \\sim \\text{Bernoulli}(\\pi_{di})\\) con \\(E(y_{di} | u_d) = \\pi_{di}\\) y \\(\\text{Var}(y_{di} | u_d) = \\sigma^2_{di} = \\pi_{di} (1 - \\pi_{di})\\). Además, \\(\\mathbf{x}_{di}\\) representa el vector \\(p \\times 1\\) de valores de las variables auxiliares a nivel de unidad. Dado que nuestro problema involucra la identificación de privaciones en forma de valores binarios \\((0,1)\\) en relación con varios indicadores, hemos optado por utilizar un modelo mixto logit Bernoulli a nivel de unidad como punto de partida. Hay varios algoritmos para ajustar este tipo de modelo, incluyendo el método de momentos simulados (MSM), el algoritmo de expectación-maximización (EM), el algoritmo de verosimilitud cuasi-penalizada (PQL) y el algoritmo de aproximación de máxima verosimilitud Laplace (ML-Laplace). Los métodos bayesianos también se pueden utilizar para ajustar modelos mixtos logit Bernoulli. Uno de los métodos más comunes es el algoritmo de Markov Chain Monte Carlo (MCMC). Este algoritmo genera muestras de los parámetros del modelo a partir de su distribución posterior, que es la distribución de los parámetros dada la evidencia. Otro método bayesiano para ajustar modelos mixtos logit Bernoulli es el enfoque de máxima verosimilitud aproximada (MAP). Este enfoque se basa en la idea de encontrar los parámetros del modelo que maximizan la verosimilitud de los datos, suponiendo que los parámetros siguen una distribución a priori. Los métodos bayesianos tienen varias ventajas sobre los métodos clásicos para ajustar modelos mixtos logit Bernoulli. En primer lugar, los métodos bayesianos pueden incorporar información previa sobre los parámetros del modelo, lo que puede mejorar la precisión de las estimaciones. En segundo lugar, los métodos bayesianos pueden proporcionar intervalos de credivilidad para los parámetros del modelo, que pueden ser utilizados para hacer inferencias sobre el modelo. En tercer lugar, los métodos bayesianos pueden ser utilizados para generar predicciones del modelo, que pueden ser utilizadas para tomar decisiones. Sin embargo, los métodos bayesianos también tienen algunas desventajas. Por ejemplo, los métodos bayesianos pueden ser más sensibles a la elección de la distribución a previas, lo que puede dificultar la obtención de estimaciones precisas. Para evitar, eso en nuestro ejercicio se hará uso de distribuciones previas no informativas, es decir, podemos definir distribuciones previas \\[ \\begin{eqnarray*} \\beta_m &amp; \\sim &amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim &amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] El modelo se debe estimar para cada una de las dimensiones. "],["estimación-de-pik_di.html", "3.1 Estimación de \\(\\pi^{k}_{di}\\)", " 3.1 Estimación de \\(\\pi^{k}_{di}\\) La estimación de \\(\\pi^{k}_{di}\\) refleja la probabilidad de que una unidad específica \\(i\\) en el dominio \\(d\\) obtenga el valor 1 en la dimensión \\(k\\). Para llevar a cabo esta estimación, seguimos el siguiente procedimiento: \\[ \\bar{Y}^{k}_d = \\pi^{k}_d = \\frac{1}{N_d} \\sum_{i=1}^{N_d} y^{k}_{di} \\] Aquí, \\(y^{k}_{di}\\) puede tomar los valores 0 ó 1, representando la ausencia (o no) de una característica específica. Ahora, podemos dividir la suma en dos partes: \\(s_d\\), que representa las unidades observadas en una muestra, y \\(s_d^c\\), que son las unidades no observados. Por lo tanto, \\[ \\begin{equation*} \\bar{Y}^{k}_d = \\pi^{k}_d = \\frac{1}{N_d}\\left(\\sum_{s_d}y^{k}_{di} + \\sum_{s^c_d}y^{k}_{di} \\right) \\end{equation*} \\] Ahora, suponga que mediante un modelo de unidad es posible realizar la predicción de \\(y^{k}_{di}\\) para las unidades no observadas. De esta manera, el estimador de \\(\\pi^{k}_d\\) se expresa como: \\[ \\hat{\\pi}^{k}_d = \\frac{1}{N_d}\\left( \\sum_{s_d}y^{k}_{di} + \\sum_{s^c_d}\\hat{y}^{k}_{di} \\right) \\] Donde, \\[\\hat{y}^{k}_{di}=E_{\\mathscr{M}}\\left(y^{k}_{di}\\mid\\boldsymbol{x}_{d},\\boldsymbol{\\beta}\\right)\\] Aquí, \\(\\mathscr{M}\\) hace referencia a la medida de probabilidad inducida por el modelo. Sin embargo, en la práctica, individualizar a las unidades observadas y no observadas en una encuesta de hogares puede ser difícil. Por lo tanto, una alternativa es realizar la predicción \\(\\hat{y}^{k}_{di}\\) para todas las observaciones en el universo. De esta manera, la estimación \\(\\hat{\\pi}^{k}_d\\) se simplifica a: \\[ \\hat{\\pi}^{k}_d = \\frac{1}{N_d}\\sum_{i=1}^{N_d}\\hat{y}^{k}_{di} \\] Este enfoque permite estimar la probabilidad \\(\\pi^{k}_d\\) en el dominio \\(d\\) en la dimensión \\(k\\) utilizando predicciones y datos disponibles en lugar de contar con información individual detallada para todos los casos. "],["pedicción-de-los-hard-estimates.html", "3.2 Pedicción de los Hard estimates", " 3.2 Pedicción de los Hard estimates Hobza y Morales (2016) definen los “hard estimates” como valores binarios (0 o 1) que indican de manera precisa si un individuo tiene o no una característica específica en relación con cada indicador de pobreza multidimensional. Estas estimaciones reflejan la naturaleza binaria de la información, facilitando el cálculo de indicadores y tasas de incidencia de pobreza. Estas estimaciones desempeñan un papel clave en la determinación de la incidencia de la pobreza multidimensional, ya que indican la presencia o ausencia de privaciones en indicadores específicos para cada individuo. Esto plantea un desafío en la estimación, ya que no se trata solo de obtener valores finales, sino de precisar si las características están presentes o no en indicadores faltantes. Con la definición de los hard estimates, y sabiendo que la estimación de \\(\\pi^{k}_{di}\\) refleja la probabilidad de que una unidad específica \\(i\\) en el dominio \\(d\\) obtenga el valor 1 en la dimensión \\(k\\) se define \\(\\hat{y}^{k}_{di} \\sim Bernoulli(\\hat{\\pi}^{k}_{di})\\) "],["estimación-puntual-del-índice-de-pobreza-multidimensional-ipm.html", "3.3 Estimación Puntual del Índice de Pobreza Multidimensional (IPM)", " 3.3 Estimación Puntual del Índice de Pobreza Multidimensional (IPM) Supongamos que el Índice de Pobreza Multidimensional está compuesto por \\(K\\) dimensiones o indicadores para cada individuo \\(i\\) en el censo. El procedimiento propuesto para estimar el IPM es el siguiente: Utilice los datos de la muestra para ajustar un modelo logit Bernoulli a nivel de unidad para cada indicador. Esto se logra mediante el uso del algoritmo de Markov Chain Monte Carlo (MCMC) con \\(L\\) iteraciones. Para cada dimensión \\(k\\) a la cual se le para ajustó un modelo logit Bernoulli a nivel de unidad con \\(L\\) iteraciones, realice la predicción de los valores \\(\\hat{y}^{k}_{di}\\) para cada individuo en el censo. Esto generará \\(L\\) realizaciones aleatorias de \\(\\hat{y}^{k}_{di}\\). Denotemos como \\(\\hat{y}_{di}^{kl}\\) a la \\(l\\)-ésima realización aleatoria de la dimensión \\(k\\) para el individuo \\(i\\) en el dominio \\(d\\). Calculamos \\(q_{di}^{l} = \\sum_{k=1}^{K} w_k \\cdot y_{di}^{kl}\\). Luego, podemos calcular \\(H_d^{l}\\), \\(A_d^{l}\\) y \\(IPM_{d}^{l}\\) utilizando las ecuaciones: \\[ IPM_{d}^{l} = \\frac{1}{N_d}\\sum_{i=1}^{N_{d}}c_{di}^{l}\\left(z\\right) \\] \\[ H_d^{l}=\\frac{1}{N_{d}}\\sum_{i=1}^{N_{d}}I\\left(q_{di}^{l}\\ge z\\right)=\\frac{N_{d}^{l}\\left(z\\right)}{N_{d}} \\] y \\[ A_{d}^{l}=\\sum_{i=1}^{N_{d}}\\frac{c_{di}^{l}\\left(z\\right)}{N^{l}_{d}\\left(z\\right)} \\] La estimación puntual de \\(H_d\\), \\(A_{d}\\) y \\(IPM_{d}\\) en cada área pequeña \\(d\\) se calcula tomando el promedio sobre cada una de las \\(L\\) iteraciones: \\[ \\hat{H}_d = \\frac{1}{L}\\sum_{l=1}^{L}H_d^l, \\] \\[ \\hat{A}_d = \\frac{1}{L}\\sum_{l=1}^{L}A_d^l \\] y \\[ \\widehat{IPM}_d = \\frac{1}{L}\\sum_{l=1}^{L}IPM_d^l \\] Dada que el modelo se estimó usando el algoritmo MCMC, es posible tener la estimación del error de estimación, de esta forma: \\[ \\widehat{Var}(\\hat{H}_d) = \\frac{1}{L}\\sum_{l=1}^{L}\\left( H^{l}_{d} -\\hat{H}_d \\right)^2, \\] \\[ \\widehat{Var}(\\hat{A}_d) = \\frac{1}{L}\\sum_{l=1}^{L}\\left( A^{l}_{d} -\\hat{A}_d \\right)^2 \\] y \\[ \\widehat{Var}(\\widehat{IPM}_d) = \\frac{1}{L}\\sum_{l=1}^{L}\\left( IPM_d^{l} -\\widehat{IPM}_d \\right)^2 \\] "],["ejemplo-aplicación-de-la-metodología..html", "3.4 Ejemplo: Aplicación de la metodología.", " 3.4 Ejemplo: Aplicación de la metodología. Para ilustrar el cálculo del Índice de Pobreza Multidimensional (IPM), empleando el algoritmo MCMC empleamos el conjunto de datos simulados a continuación. Consideremos un escenario con diez unidades (\\(N = 10\\)), a las cuales se les han asignado nueve dimensiones distintas (\\(K = 9\\)). Estas dimensiones están ponderadas de acuerdo con el vector \\(w = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2)\\). # Definición de parámetros K &lt;- 9 # Número de dimensiones N &lt;- 10 # Número de personas w &lt;- c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2) # Ponderaciones para cada dimensión A continuación se realiza la simulación de la matriz de variables dicótomicas para las diez unidades, para ello asumiremos que \\(\\hat{\\pi}^{k}_{di} = (0.5, 0.2, 0.3, 0.4, 0.1, 0.9, 0.2, 0.7, 0.1)\\) que fueron estimados mediante modelos mixtos logit Bernoulli, Bayesiano con \\(L = 5\\). Con las que se obtienes las siguientes matrices de Hard estimates set.seed(1234) library(purrr) pi_di = c(0.5, 0.2, 0.3, 0.4, 0.1, 0.9, 0.2, 0.7,0.1) # Generación de datos simulados ## Iteración 1 data_1 &lt;- data.frame( y1 = as.numeric(rbernoulli(n = N, p= pi_di[1])), y2 = as.numeric(rbernoulli(n = N, p= pi_di[2])), y3 = as.numeric(rbernoulli(n = N, p= pi_di[3])), y4 = as.numeric(rbernoulli(n = N, p= pi_di[4])), y5 = as.numeric(rbernoulli(n = N, p= pi_di[5])), y6 = as.numeric(rbernoulli(n = N, p= pi_di[6])), y7 = as.numeric(rbernoulli(n = N, p= pi_di[7])), y8 = as.numeric(rbernoulli(n = N, p= pi_di[8])), y9 = as.numeric(rbernoulli(n = N, p= pi_di[9])) ) rownames(data_1)&lt;- paste0(&quot;P&quot;,1:N) Tabla 3.1: Iteración (l=1) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 0 0 0 0 0 1 0 1 P2 1 0 0 0 0 1 0 1 0 P3 1 0 0 0 0 1 0 0 0 P4 1 1 0 0 0 1 0 1 0 P5 1 0 0 0 0 1 0 0 0 P6 1 1 1 1 0 1 0 1 0 P7 0 0 0 0 0 1 0 1 0 P8 0 0 1 0 0 1 0 0 0 P9 1 0 1 1 0 1 0 1 0 P10 1 0 0 1 0 1 0 1 0 Tabla 3.2: Iteración (l=2) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 0 1 1 1 1 0 1 0 P2 1 0 0 1 0 1 0 1 0 P3 0 0 1 1 0 1 0 1 0 P4 0 0 0 1 0 1 1 0 0 P5 0 0 0 0 1 1 0 0 0 P6 1 0 1 0 0 1 1 1 0 P7 0 0 1 0 1 1 0 1 0 P8 0 0 0 0 0 1 1 0 0 P9 0 0 0 0 0 1 0 1 0 P10 1 0 1 0 0 1 0 1 0 Tabla 3.3: Iteración (l=3) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 0 0 0 0 1 0 1 0 P2 0 1 0 0 0 1 0 1 0 P3 1 0 0 0 0 1 0 0 0 P4 0 1 1 1 0 1 0 0 0 P5 1 1 0 0 0 1 1 0 0 P6 0 1 1 1 0 1 0 1 0 P7 1 1 0 1 0 1 0 0 0 P8 1 0 0 1 0 1 0 0 0 P9 0 1 0 0 0 1 1 1 0 P10 1 0 1 1 0 1 0 1 0 Tabla 3.4: Iteración (l=4) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 0 0 0 1 1 0 1 0 P2 1 0 0 1 0 1 1 0 0 P3 0 1 1 0 0 1 1 1 0 P4 1 0 0 0 0 1 0 1 0 P5 0 0 0 1 0 1 0 1 1 P6 1 0 1 0 0 1 0 1 1 P7 1 0 0 0 0 1 0 0 0 P8 1 0 0 1 0 1 0 1 0 P9 0 0 0 0 0 1 1 1 0 P10 0 1 0 1 0 1 0 0 0 Tabla 3.5: Iteración (l=5) y1 y2 y3 y4 y5 y6 y7 y8 y9 P1 0 1 0 1 0 1 0 1 0 P2 1 0 0 1 0 1 1 1 0 P3 0 1 0 1 0 1 0 1 0 P4 0 0 0 1 0 1 0 1 0 P5 1 0 0 0 0 1 1 0 1 P6 1 0 0 1 0 1 0 1 0 P7 1 0 0 0 0 1 0 1 0 P8 0 0 0 0 0 1 0 1 0 P9 1 0 1 0 0 1 0 1 0 P10 1 0 1 0 0 1 0 1 0 A continuación se realiza el calculo de \\(q^l_i\\), \\(I\\left( q_{i}^{l} &gt; z \\right)\\) y \\(c_{i}^{l}\\left(z\\right)\\) usando las ecuaciones dadas previamente y \\(z=0.4\\). # Vector q de ponderaciones por dimensiones q1 &lt;- as.matrix(data_1) %*% w q2 &lt;- as.matrix(data_2) %*% w q3 &lt;- as.matrix(data_3) %*% w q4 &lt;- as.matrix(data_4) %*% w q5 &lt;- as.matrix(data_5) %*% w Ind1 &lt;- ifelse(q1 &gt;= 0.4,1,0) Ind2 &lt;- ifelse(q2 &gt;= 0.4,1,0) Ind3 &lt;- ifelse(q3 &gt;= 0.4,1,0) Ind4 &lt;- ifelse(q4 &gt;= 0.4,1,0) Ind5 &lt;- ifelse(q5 &gt;= 0.4,1,0) c1 &lt;- ifelse(Ind1 == 1,q1,0) c2 &lt;- ifelse(Ind2 == 1,q2,0) c3 &lt;- ifelse(Ind3 == 1,q3,0) c4 &lt;- ifelse(Ind4 == 1,q4,0) c5 &lt;- ifelse(Ind5 == 1,q5,0) datos &lt;- data.frame(q1, q2, q3, q4, q5, Ind1, Ind2, Ind3, Ind4, Ind5, c1, c2, c3, c4, c5) q1 q2 q3 q4 q5 Ind1 Ind2 Ind3 Ind4 Ind5 c1 c2 c3 c4 c5 P1 0.3 0.5 0.2 0.3 0.4 0 1 0 0 1 0.0 0.5 0.0 0.0 0.4 P2 0.3 0.4 0.3 0.4 0.5 0 1 0 1 1 0.0 0.4 0.0 0.4 0.5 P3 0.2 0.4 0.2 0.5 0.4 0 1 0 1 1 0.0 0.4 0.0 0.5 0.4 P4 0.4 0.3 0.4 0.3 0.3 1 0 1 0 0 0.4 0.0 0.4 0.0 0.0 P5 0.2 0.2 0.4 0.5 0.5 0 0 1 1 1 0.0 0.0 0.4 0.5 0.5 P6 0.6 0.5 0.5 0.6 0.4 1 1 1 1 1 0.6 0.5 0.5 0.6 0.4 P7 0.2 0.4 0.4 0.2 0.3 0 1 1 0 0 0.0 0.4 0.4 0.0 0.0 P8 0.2 0.2 0.3 0.4 0.2 0 0 0 1 0 0.0 0.0 0.0 0.4 0.0 P9 0.5 0.2 0.4 0.3 0.4 1 0 1 0 1 0.5 0.0 0.4 0.0 0.4 P10 0.4 0.4 0.5 0.3 0.4 1 1 1 0 1 0.4 0.4 0.5 0.0 0.4 Ahora se calcula \\(IPM^l\\) , \\(H^l\\) y \\(A^l\\), esto es: IPM_l &lt;- colMeans(datos[,11:15]) Nz_l &lt;- colSums(datos[,6:10]) H_l &lt;- Nz_l/N A_l &lt;- colSums(datos[,11:15])/Nz_l tab_l &lt;- data.frame(IPM_l, Nz_l, H_l, A_l, HA_l = H_l*A_l) rownames(tab_l) &lt;- paste0(&quot;l = &quot;, 1:nrow(tab_l)) tba(tab_l) IPM_l Nz_l H_l A_l HA_l l = 1 0.19 4 0.4 0.4750 0.19 l = 2 0.26 6 0.6 0.4333 0.26 l = 3 0.26 6 0.6 0.4333 0.26 l = 4 0.24 5 0.5 0.4800 0.24 l = 5 0.30 7 0.7 0.4286 0.30 Por último se realiza el calculo de las estimaciones puntuales y su varianza para \\(H\\), \\(A\\) y \\(IPM\\), esto es: estimacion &lt;- data.frame(H = mean(H_l), H_sd = sd(H_l), A = mean(A_l), A_sd = sd(A_l), IPM = mean(IPM_l), IPM_sd = sd(IPM_l)) Tabla 3.6: Estimaciones H H_sd A A_sd IPM IPM_sd 0.56 0.114 0.45 0.0252 0.25 0.04 "],["aplicación-índice-de-pobreza-multidimensional-en-colombia..html", "Capítulo 4 Aplicación: Índice de Pobreza Multidimensional en Colombia.", " Capítulo 4 Aplicación: Índice de Pobreza Multidimensional en Colombia. Nos centramos en la incidencia de la pobreza multidimensional descrito previamente. En este caso, requerimos \\(K = 9\\) indicadores que se miden como privaciones: \\(y_{di}^{k} = 1\\) si la persona tiene la privación y \\(y_{di}^{k} = 0\\) si la persona no ha tenido la privación. El índice requiere información para cada individuo \\(i = 1, \\ldots, N_d\\) en los dominios \\(d = 1, \\ldots, D\\), donde \\(N_d\\) denota el tamaño de la población del dominio \\(d\\). La función indicadora \\(I(\\cdot)\\) es igual a 1 cuando se cumple la condición \\(q_{di} \\ge z\\). Para este estudio, utilizamos el valor de 0.4 para \\(z\\), es decir, \\(I(\\cdot)\\) es igual a 1 cuando \\(q_{di} \\ge 0.4\\). \\(q_{di}\\) es una cantidad ponderada que considera los \\(K = 9\\) indicadores que conforman el índice. El valor de \\(q_{di}\\) el dominio \\(d\\) se calcula como: \\[ q_{di} = \\frac{1}{12}\\sum_{k =1}^{12}y_{di}^{k} \\] Donde: Categoría Variable Descripción Educación nbi_hnolee_ee Al menos un mayor de 10 años no sabe leer en el hogar nbi_hlogroeduc_ee Todos los integrantes del hogar entre 18 y 64 están privados en la nbi_educ individual nbi_heducninios Al menos un menor de edad no asiste o está rezagado Vivienda nbi_hhacina nbi_henergia nbi_htic Salud nbi_hagua_ee nbi_hsaneamiento_ee nbi_hsalud_ee Empleo nbi_hpartemp Al menos un individuo del hogar tiene empleo temporal según la condición y edad nbi_hempe Todos los individuos ocupados del hogar cumplen ciertas condiciones de empleo nbi_hjub Al menos un individuo del hogar es jubilado según edad y pensión Los datos de la encuesta y el censo han sido preparados previamente, la información sobre la cual realizaremos la predicción corresponde a Colombia en el 2019 encuesta_ipm &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Encuestas/encuesta_nbi.rds&quot;) statelevel_predictors_df &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/statelevel_predictors_df_dam2.rds&quot;) byAgrega &lt;- c(&quot;dam&quot;, &quot;dam2&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;etnia&quot;, &quot;anoest&quot;, &quot;edad&quot;) Agregando la información para los municipios de Colombia para los indicadores que conformarán el IPM names_ipm &lt;- c( &quot;nbi_hnolee_ee&quot; , &quot;nbi_hlogroeduc_ee&quot; , &quot;nbi_heducninios&quot; , &quot;nbi_hhacina&quot; , &quot;nbi_henergia&quot; , &quot;nbi_htic&quot; , &quot;nbi_hagua_ee&quot; , &quot;nbi_hsaneamiento_ee&quot; , &quot;nbi_hsalud_ee&quot; , &quot;nbi_hpartemp&quot; , &quot;nbi_hempe&quot; , &quot;nbi_hjub&quot; ) encuesta_df &lt;- map(setNames(names_ipm,names_ipm), function(y){ encuesta_ipm$temp &lt;- as.numeric(encuesta_ipm[[y]]) encuesta_ipm %&gt;% group_by_at(all_of(byAgrega)) %&gt;% summarise(n = n(), yno = sum(temp), ysi = n - yno, .groups = &quot;drop&quot;) %&gt;% inner_join(statelevel_predictors_df, by = c(&quot;dam&quot;,&quot;dam2&quot;)) }) La base resultante quedan de la siguiente forma: Tabla 4.1: nbi_hnolee_ee dam dam2 area sexo etnia anoest edad n yno ysi area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 11 11001 1 1 3 3 2 2439 51 2388 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 22.0069 9.1869 19.7751 0.5697 61.3823 259.2423 47 47001 1 2 3 3 2 2386 167 2219 0.9150 0.5158 0.2705 0.2125 0.1913 0.0719 0.0354 0.2539 0.4149 0.1837 0.0169 0.3002 0.0312 0.0364 0.2845 0.0015 4.3364 0.4577 1.7512 0.3278 210.3355 611.8750 23 23001 1 2 3 3 2 2359 257 2102 0.8192 0.5149 0.2631 0.2146 0.1961 0.0761 0.0170 0.2857 0.3634 0.1920 0.0072 0.1251 0.1412 0.0657 0.2275 0.0010 3.8284 19.0431 1.0209 0.4172 48.4391 234.8668 47 47001 1 1 3 3 2 2333 185 2148 0.9150 0.5158 0.2705 0.2125 0.1913 0.0719 0.0354 0.2539 0.4149 0.1837 0.0169 0.3002 0.0312 0.0364 0.2845 0.0015 4.3364 0.4577 1.7512 0.3278 210.3355 611.8750 11 11001 1 2 3 3 2 2246 58 2188 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 22.0069 9.1869 19.7751 0.5697 61.3823 259.2423 23 23001 1 1 3 3 2 2100 250 1850 0.8192 0.5149 0.2631 0.2146 0.1961 0.0761 0.0170 0.2857 0.3634 0.1920 0.0072 0.1251 0.1412 0.0657 0.2275 0.0010 3.8284 19.0431 1.0209 0.4172 48.4391 234.8668 Tabla 4.2: nbi_hlogroeduc_ee dam dam2 area sexo etnia anoest edad n yno ysi area1 sexo2 edad2 edad3 edad4 edad5 etnia2 anoest2 anoest3 anoest4 etnia1 tiene_acueducto piso_tierra alfabeta hacinamiento tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 11 11001 1 1 3 3 2 2439 693 1746 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 22.0069 9.1869 19.7751 0.5697 61.3823 259.2423 47 47001 1 2 3 3 2 2386 627 1759 0.9150 0.5158 0.2705 0.2125 0.1913 0.0719 0.0354 0.2539 0.4149 0.1837 0.0169 0.3002 0.0312 0.0364 0.2845 0.0015 4.3364 0.4577 1.7512 0.3278 210.3355 611.8750 23 23001 1 2 3 3 2 2359 695 1664 0.8192 0.5149 0.2631 0.2146 0.1961 0.0761 0.0170 0.2857 0.3634 0.1920 0.0072 0.1251 0.1412 0.0657 0.2275 0.0010 3.8284 19.0431 1.0209 0.4172 48.4391 234.8668 47 47001 1 1 3 3 2 2333 535 1798 0.9150 0.5158 0.2705 0.2125 0.1913 0.0719 0.0354 0.2539 0.4149 0.1837 0.0169 0.3002 0.0312 0.0364 0.2845 0.0015 4.3364 0.4577 1.7512 0.3278 210.3355 611.8750 11 11001 1 2 3 3 2 2246 740 1506 0.9979 0.5219 0.2690 0.2316 0.2251 0.0886 0.0093 0.2098 0.3810 0.2938 0.0027 0.0219 0.0026 0.0143 0.0848 0.0176 22.0069 9.1869 19.7751 0.5697 61.3823 259.2423 23 23001 1 1 3 3 2 2100 580 1520 0.8192 0.5149 0.2631 0.2146 0.1961 0.0761 0.0170 0.2857 0.3634 0.1920 0.0072 0.1251 0.1412 0.0657 0.2275 0.0010 3.8284 19.0431 1.0209 0.4172 48.4391 234.8668 "],["definiendo-de-los-modelos-en-stan..html", "4.1 Definiendo de los modelos en Stan.", " 4.1 Definiendo de los modelos en Stan. Para cada dimensión que compone el IPM se ajusta un modelo mixtos logit Bernoulli estimando mediante técnicas bayesiana. En este código se incluye el uso de la función future_map que permite procesar en paralelo cada modelo O puede compilar cada por separado, en nuestro caso se proceso cada modelo por separado. library(furrr) names_cov &lt;- statelevel_predictors_df %&gt;% dplyr::select(-dam,-dam2) %&gt;% names() names_cov &lt;- c(&quot;sexo&quot;,&quot;area&quot;,names_cov[16:19]) efec_aleat &lt;- paste0(&quot;(1|&quot;, c(&quot;dam&quot;, &quot;etnia&quot;), &quot;)&quot;, collapse = &quot;+&quot;) formula_mod &lt;- formula(paste( &quot; cbind(yno, ysi) ~&quot;, efec_aleat, &quot;+&quot;, paste0(names_cov, collapse = &quot; + &quot;) )) formula_mod Ejecutando los modelos run_bayesian_model &lt;- function(variable, data) { fit &lt;- stan_glmer( formula = formula_mod, family = binomial(link = &quot;logit&quot;), data = data[[variable]], cores = 4, chains = 4, iter = 500, open_progress = TRUE ) saveRDS(fit, file = paste0(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_&quot;, variable, &quot;.rds&quot;)) } for (variable in nbi_hogar) { run_bayesian_model(variable, encuesta_df) } 4.1.1 Prueba del \\(\\hat{R}\\) En modelos Bayesianos, la prueba Rhat es utilizada para evaluar la convergencia de las cadenas MCMC. La idea es verificar si múltiples cadenas MCMC han convergido al mismo valor de la distribución posterior. 4.1.1.1 Fórmula de Rhat La fórmula para calcular Rhat es la siguiente: \\[ \\hat{R} = \\sqrt{\\frac{\\text{Varianza entre cadenas}}{\\text{Varianza dentro de cadenas}}} \\] Donde: - Varianza entre cadenas: Varianza de los valores de un parámetro entre todas las cadenas MCMC. - Varianza dentro de cadenas: Varianza de los valores de un parámetro dentro de cada cadena MCMC. 4.1.1.2 Interpretación de Rhat Si \\(\\hat{R}\\) es cercano a 1, indica buena convergencia de las cadenas. Valores mayores a 1.1 pueden indicar problemas de convergencia y la necesidad de revisar las cadenas y el modelo. library(rstantools) library(bayesplot) for(ii in 1:12){ modelo_rds &lt;- paste0(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_&quot;, names_ipm[ii], &quot;.rds&quot;) s &lt;- rhat(readRDS(modelo_rds)) s &lt;- mcmc_rhat(s) + ggtitle(names_ipm[ii]) print(s) } Terminado la compilación de los modelos después de realizar validaciones sobre esto, pasamos hacer las predicciones en el censo. "],["proceso-para-la-predicción-pi_dikl.html", "4.2 Proceso para la predicción \\(\\pi_{di}^{kl}\\)", " 4.2 Proceso para la predicción \\(\\pi_{di}^{kl}\\) Los modelos fueron compilados de manera separada, por tanto, disponemos de un objeto .rds por cada dimensión del IPM crear_epred_mat_dummy &lt;- function(variable, newdata) { # Paso 1: Cargar el modelo modelo_rds &lt;- paste0(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/fit_&quot;, variable, &quot;.rds&quot;) ruta_guardado &lt;- paste0(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_&quot;, variable, &quot;.rds&quot;) fit &lt;- readRDS(file = modelo_rds) # Paso 2: Generar epred_mat epred_mat &lt;- posterior_epred( fit, newdata = newdata, type = &quot;response&quot;, allow.new.levels = TRUE ) # Paso 3: Generar epred_mat_dummy epred_mat_dummy &lt;- rbinom(n = nrow(epred_mat) * ncol(epred_mat), 1, epred_mat) epred_mat_dummy &lt;- matrix(epred_mat_dummy, nrow = nrow(epred_mat), ncol = ncol(epred_mat)) # Guardar epred_mat_dummy como un archivo .rds saveRDS(epred_mat_dummy, file = ruta_guardado) cat(ruta_guardado, &quot;\\n&quot;) } Note que la función se encarga de leer los modelos que fueron estimados previamente, luego se obtienen las \\(L\\) predicciones de \\(\\pi_{di}^{kl}\\), epred_mat &lt;- posterior_epred( fit_agua, newdata = newdata, type = &quot;response&quot;, allow.new.levels = TRUE ) Los resultados anteriores se deben procesarse para obtener los hard estimates, es decir, términos de carencia (1) y no carencia (0) para la \\(k-esima\\) carencias. Lo que se realiza con el código epred_mat_dummy &lt;- rbinom(n = nrow(epred_mat) * ncol(epred_mat), 1, epred_mat) epred_mat_dummy &lt;- matrix(epred_mat_dummy, nrow = nrow(epred_mat), ncol = ncol(epred_mat)) Ahora, debemos leer la información del censo y crear los post-estrato censo_ipm &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Censo/censo_COL.rds&quot;) %&gt;% rename(dam = depto, dam2 = mpio) %&gt;% group_by(dam, dam2, area, sexo, edad, etnia, anoest) %&gt;% summarise(n = sum(n), .groups = &quot;drop&quot;) statelevel_predictors_df &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/statelevel_predictors_df_dam2.rds&quot;) Para realizar la predicción en el censo debemos incluir la información auxiliar poststrat_df &lt;- left_join(censo_ipm, statelevel_predictors_df, by = c(&quot;dam&quot;, &quot;dam2&quot;)) Ahora, para obtener los hard estimates usamos el siguinte código for(ii in 1:12){ crear_epred_mat_dummy(names_ipm[ii],poststrat_df) # OK } "],["calculando-q_dil-ileft-q_dil-ge-z-right-y-c_dilleftzright.html", "4.3 Calculando \\(q_{di}^{l}\\), \\(I\\left( q_{di}^{l} \\ge z \\right)\\) y \\(c_{di}^{l}\\left(z\\right)\\)", " 4.3 Calculando \\(q_{di}^{l}\\), \\(I\\left( q_{di}^{l} \\ge z \\right)\\) y \\(c_{di}^{l}\\left(z\\right)\\) Dado que los hard estimates fueron organizados en matrices, el calculo de \\(q^{l}_{id}\\) es una simple operación matricial la cual se muestra a continuación epred_mat_dummy_hnolee &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hnolee_ee.rds&quot;) epred_mat_dummy_hlogroeduc &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hlogroeduc_ee.rds&quot;) epred_mat_dummy_heducninios &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_heducninios.rds&quot;) epred_mat_dummy_hhacina &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hhacina.rds&quot;) epred_mat_dummy_henergia &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_henergia.rds&quot;) epred_mat_dummy_htic &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_htic.rds&quot;) epred_mat_dummy_hagua &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hagua_ee.rds&quot;) epred_mat_dummy_hsaneamiento &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hsaneamiento_ee.rds&quot;) epred_mat_dummy_hsalud &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hsalud_ee.rds&quot;) epred_mat_dummy_hpartemp &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hpartemp.rds&quot;) epred_mat_dummy_hempe &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hempe.rds&quot;) epred_mat_dummy_hjub &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/epred_mat_dummy_nbi_hjub.rds&quot;) chain_q &lt;- (1/12)*(epred_mat_dummy_hnolee + epred_mat_dummy_hlogroeduc + epred_mat_dummy_heducninios + epred_mat_dummy_hhacina + epred_mat_dummy_henergia + epred_mat_dummy_htic + epred_mat_dummy_hagua + epred_mat_dummy_hsaneamiento + epred_mat_dummy_hsalud + epred_mat_dummy_hpartemp + epred_mat_dummy_hempe + epred_mat_dummy_hjub ) Ahora, es posible tener el calculo de \\(I\\left( q_{di}^{l} \\ge z \\right)\\), tomando como umbral \\(z=0.4\\). chain_Ind &lt;- chain_q chain_Ind[chain_Ind &lt; 0.4] &lt;- 0 chain_Ind[chain_Ind != 0] &lt;- 1 seguidamente calculamos \\(c_{di}^{l}\\left(z\\right)\\) chain_ci &lt;- matrix(0,nrow = nrow(chain_q), ncol = ncol(chain_q)) chain_ci[chain_Ind == 1] &lt;- chain_q[chain_Ind == 1] datos&lt;-data.frame(t(chain_q[1:5,1:10]), t(chain_Ind[1:5,1:10]), t(chain_ci[1:5,1:10]), N = censo_ipm$n[1:10] ) colnames(datos) &lt;- c(paste0(&quot;q&quot;,1:5), paste0(&quot;Ind&quot;,1:5),paste0(&quot;c&quot;,1:5),&quot;N&quot;) tba(datos, &quot;Cadenas obtenidas&quot;) Tabla 4.3: Cadenas obtenidas q1 q2 q3 q4 q5 Ind1 Ind2 Ind3 Ind4 Ind5 c1 c2 c3 c4 c5 N 0.3333 0.3333 0.2500 0.3333 0.5000 0 0 0 0 1 0.0000 0.0000 0.0000 0 0.5 1 0.4167 0.2500 0.4167 0.2500 0.3333 1 0 1 0 0 0.4167 0.0000 0.4167 0 0.0 1 0.2500 0.3333 0.3333 0.3333 0.3333 0 0 0 0 0 0.0000 0.0000 0.0000 0 0.0 9 0.3333 0.3333 0.5833 0.2500 0.3333 0 0 1 0 0 0.0000 0.0000 0.5833 0 0.0 1 0.3333 0.3333 0.2500 0.0833 0.0000 0 0 0 0 0 0.0000 0.0000 0.0000 0 0.0 5 0.2500 0.3333 0.4167 0.3333 0.3333 0 0 1 0 0 0.0000 0.0000 0.4167 0 0.0 22 0.2500 0.1667 0.3333 0.1667 0.2500 0 0 0 0 0 0.0000 0.0000 0.0000 0 0.0 9 0.3333 0.5000 0.4167 0.2500 0.2500 0 1 1 0 0 0.0000 0.5000 0.4167 0 0.0 76 0.5000 0.4167 0.1667 0.2500 0.3333 1 1 0 0 0 0.5000 0.4167 0.0000 0 0.0 796 0.3333 0.0833 0.3333 0.1667 0.3333 0 0 0 0 0 0.0000 0.0000 0.0000 0 0.0 3549 "],["estimación-de-h-a-e-ipm.html", "4.4 Estimación de \\(H\\), \\(A\\) e \\(IPM\\)", " 4.4 Estimación de \\(H\\), \\(A\\) e \\(IPM\\) Para este proceso debemos realizar sumas ponderadas, dado que cada registro de la base de datos representa un grupo de observaciones con las mismas características. numIPM &lt;- t(chain_ci) %&gt;% as.data.frame() %&gt;% mutate_all(~ . * censo_ipm$n) %&gt;% as.matrix() chain_N &lt;- t(chain_Ind) %&gt;% as.data.frame() %&gt;% mutate_all(~ . * censo_ipm$n) %&gt;% as.matrix() IPM_l &lt;- colSums(numIPM)/sum(censo_ipm$n) Nz_l &lt;- colSums(chain_N) H_l &lt;- Nz_l/sum(censo_ipm$n) A_l &lt;- colSums(numIPM)/Nz_l Tabla 4.4: l-iteraciones IPM_l Nz_l H_l A_l HA_l l = 1 0.0827 5796711 0.1696 0.4877 0.0827 l = 2 0.0819 5728479 0.1676 0.4889 0.0819 l = 3 0.0780 5436367 0.1590 0.4902 0.0780 l = 4 0.0924 6485925 0.1898 0.4871 0.0924 l = 5 0.0790 5520098 0.1615 0.4892 0.0790 l = 6 0.0810 5655742 0.1655 0.4894 0.0810 l = 7 0.0860 6045415 0.1769 0.4864 0.0860 l = 8 0.0815 5689540 0.1665 0.4898 0.0815 l = 9 0.0822 5757858 0.1685 0.4882 0.0822 l = 10 0.0804 5606016 0.1640 0.4900 0.0804 Por último se realiza las estimaciones puntuales y varianza para \\(H\\), \\(A\\) y \\(IPM\\), esto es: estimacion &lt;- data.frame(H = mean(H_l), H_sd = sd(H_l), A = mean(A_l), A_sd = sd(A_l), IPM = mean(IPM_l), IPM_sd = sd(IPM_l)) Tabla 4.5: Estimaciones Nacionales H H_sd A A_sd IPM IPM_sd 0.1688 0.0053 0.4885 0.0023 0.0825 0.0024 "],["estimaciones-desagregadas-del-ipm.html", "4.5 Estimaciones desagregadas del IPM", " 4.5 Estimaciones desagregadas del IPM Para realizar las estimaciones desagregadas se desarrollo una función que facilita el calculo, la estructura general el proceso es repetir el proceso anterior por subgrupos, por ejemplo, departamento (dam) source(&quot;Modelo_bayes_HxA_Hogar/0funciones/Estimar_ipm.R&quot;) ipm_dam &lt;- estime_IPM( poststrat = censo_ipm, chain_ci = chain_ci, chain_ind = chain_ind, byMap = &quot;dam&quot; ) %&gt;% data.frame() Tabla 4.6: Estimaciones por departamento dam H H_sd A A_sd IPM IPM_sd 05 0.1204 0.0104 0.4792 0.0047 0.0577 0.0046 08 0.0964 0.0274 0.4562 0.0117 0.0438 0.0119 11 0.0115 0.0248 0.4398 0.0253 0.0049 0.0108 13 0.2465 0.0212 0.4911 0.0064 0.1210 0.0094 15 0.2092 0.0094 0.4668 0.0030 0.0976 0.0042 17 0.1351 0.0135 0.4673 0.0067 0.0631 0.0060 18 0.2743 0.0273 0.4836 0.0079 0.1326 0.0123 19 0.4268 0.0128 0.5003 0.0040 0.2135 0.0062 20 0.2184 0.0243 0.4789 0.0074 0.1045 0.0107 23 0.4002 0.0190 0.5081 0.0054 0.2033 0.0089 25 0.1244 0.0085 0.4673 0.0038 0.0581 0.0038 27 0.6219 0.0309 0.5297 0.0061 0.3293 0.0146 41 0.2140 0.0175 0.4707 0.0057 0.1007 0.0080 44 0.4752 0.0205 0.5337 0.0106 0.2536 0.0117 47 0.2400 0.0259 0.4786 0.0069 0.1148 0.0115 50 0.1741 0.0194 0.4791 0.0068 0.0833 0.0086 52 0.3486 0.0152 0.4940 0.0048 0.1722 0.0070 54 0.2363 0.0326 0.4843 0.0088 0.1142 0.0143 63 0.0741 0.0194 0.4538 0.0101 0.0335 0.0084 66 0.1087 0.0189 0.4703 0.0095 0.0510 0.0084 68 0.1599 0.0109 0.4812 0.0050 0.0769 0.0048 70 0.3866 0.0201 0.5055 0.0053 0.1954 0.0092 73 0.1895 0.0171 0.4823 0.0060 0.0913 0.0075 76 0.0901 0.0127 0.4646 0.0066 0.0418 0.0055 81 0.3387 0.0663 0.4869 0.0142 0.1653 0.0346 85 0.2683 0.0542 0.4808 0.0126 0.1293 0.0277 86 0.4499 0.0619 0.5074 0.0139 0.2289 0.0361 88 0.1822 0.0539 0.4686 0.0187 0.0856 0.0265 91 0.7166 0.0732 0.5593 0.0146 0.4008 0.0420 94 0.6856 0.0696 0.5554 0.0180 0.3811 0.0433 95 0.4829 0.0740 0.5112 0.0174 0.2472 0.0406 97 0.8381 0.0504 0.5863 0.0210 0.4917 0.0384 99 0.7162 0.0535 0.5564 0.0242 0.3991 0.0404 Otra estimación desagregada que es posible obtener es la combinación por departamento y sexo, para ellos se usa la sintaxis. ipm_dam_sexo &lt;- estime_IPM( poststrat = censo_ipm, chain_ci = chain_ci, chain_ind = chain_ind, byMap = c(&quot;dam&quot;, &quot;sexo&quot;) ) %&gt;% data.frame() Tabla 4.7: Estimaciones por departamento y sexo dam sexo H H_sd A A_sd IPM IPM_sd 05 1 0.1360 0.0152 0.4819 0.0057 0.0655 0.0067 05 2 0.1063 0.0136 0.4765 0.0063 0.0506 0.0059 08 1 0.1030 0.0388 0.4594 0.0145 0.0470 0.0169 08 2 0.0903 0.0389 0.4557 0.0156 0.0408 0.0169 11 1 0.0133 0.0366 0.4425 0.0304 0.0057 0.0160 11 2 0.0099 0.0317 0.4422 0.0316 0.0043 0.0137 13 1 0.2684 0.0314 0.4945 0.0085 0.1325 0.0138 13 2 0.2255 0.0292 0.4880 0.0091 0.1099 0.0130 15 1 0.2291 0.0133 0.4683 0.0040 0.1073 0.0060 15 2 0.1903 0.0130 0.4651 0.0043 0.0885 0.0058 17 1 0.1516 0.0186 0.4686 0.0088 0.0710 0.0084 17 2 0.1199 0.0181 0.4662 0.0095 0.0558 0.0080 18 1 0.3079 0.0401 0.4865 0.0108 0.1496 0.0182 18 2 0.2401 0.0391 0.4806 0.0110 0.1152 0.0176 19 1 0.4497 0.0182 0.5018 0.0057 0.2256 0.0089 19 2 0.4047 0.0185 0.4988 0.0057 0.2018 0.0089 20 1 0.2367 0.0349 0.4820 0.0093 0.1139 0.0155 20 2 0.2008 0.0368 0.4765 0.0107 0.0955 0.0162 23 1 0.4251 0.0287 0.5111 0.0076 0.2172 0.0133 23 2 0.3761 0.0276 0.5051 0.0078 0.1899 0.0127 25 1 0.1388 0.0119 0.4694 0.0048 0.0651 0.0053 25 2 0.1106 0.0113 0.4650 0.0052 0.0514 0.0049 27 1 0.6493 0.0392 0.5330 0.0080 0.3459 0.0187 27 2 0.5959 0.0463 0.5265 0.0087 0.3135 0.0219 41 1 0.2358 0.0242 0.4726 0.0077 0.1114 0.0111 41 2 0.1927 0.0242 0.4686 0.0085 0.0902 0.0109 44 1 0.4868 0.0287 0.5358 0.0144 0.2608 0.0162 44 2 0.4644 0.0290 0.5318 0.0154 0.2469 0.0164 47 1 0.2587 0.0369 0.4815 0.0091 0.1244 0.0165 47 2 0.2216 0.0356 0.4761 0.0098 0.1053 0.0158 50 1 0.1976 0.0272 0.4812 0.0086 0.0950 0.0121 50 2 0.1503 0.0257 0.4771 0.0097 0.0716 0.0112 52 1 0.3686 0.0223 0.4958 0.0064 0.1827 0.0104 52 2 0.3299 0.0216 0.4923 0.0067 0.1624 0.0099 54 1 0.2598 0.0475 0.4879 0.0117 0.1264 0.0208 54 2 0.2141 0.0450 0.4817 0.0122 0.1028 0.0196 63 1 0.0850 0.0296 0.4564 0.0129 0.0386 0.0129 63 2 0.0642 0.0252 0.4524 0.0131 0.0289 0.0110 66 1 0.1221 0.0276 0.4723 0.0127 0.0575 0.0123 66 2 0.0967 0.0260 0.4697 0.0141 0.0452 0.0114 68 1 0.1808 0.0158 0.4835 0.0067 0.0874 0.0070 68 2 0.1404 0.0151 0.4788 0.0069 0.0672 0.0066 70 1 0.4114 0.0285 0.5079 0.0070 0.2088 0.0132 70 2 0.3620 0.0272 0.5030 0.0078 0.1820 0.0123 73 1 0.2107 0.0238 0.4846 0.0078 0.1020 0.0105 73 2 0.1691 0.0242 0.4801 0.0086 0.0810 0.0106 76 1 0.0997 0.0193 0.4669 0.0087 0.0465 0.0084 76 2 0.0817 0.0170 0.4631 0.0090 0.0377 0.0074 81 1 0.3638 0.0764 0.4896 0.0173 0.1784 0.0395 81 2 0.3132 0.0721 0.4844 0.0178 0.1519 0.0363 85 1 0.2912 0.0631 0.4838 0.0149 0.1411 0.0318 85 2 0.2452 0.0603 0.4782 0.0146 0.1174 0.0295 86 1 0.4783 0.0663 0.5100 0.0157 0.2445 0.0386 86 2 0.4212 0.0647 0.5046 0.0145 0.2131 0.0364 88 1 0.1913 0.0674 0.4705 0.0238 0.0903 0.0329 88 2 0.1740 0.0612 0.4671 0.0244 0.0814 0.0294 91 1 0.7325 0.0897 0.5626 0.0191 0.4118 0.0494 91 2 0.6990 0.0902 0.5563 0.0190 0.3886 0.0496 94 1 0.7021 0.0786 0.5592 0.0223 0.3927 0.0476 94 2 0.6670 0.0871 0.5516 0.0226 0.3679 0.0503 95 1 0.5219 0.0857 0.5159 0.0208 0.2695 0.0466 95 2 0.4361 0.0922 0.5059 0.0210 0.2205 0.0467 97 1 0.8411 0.0558 0.5898 0.0272 0.4964 0.0425 97 2 0.8345 0.0640 0.5823 0.0267 0.4862 0.0454 99 1 0.7296 0.0600 0.5576 0.0289 0.4073 0.0443 99 2 0.7003 0.0623 0.5552 0.0302 0.3894 0.0452 "],["estimaciones-por-dimension-del-ipm.html", "4.6 Estimaciones por dimension del IPM", " 4.6 Estimaciones por dimension del IPM Dado que el Índice de Pobreza Multidimensional (IPM) está compuesto por diversas dimensiones, resulta fundamental analizar cada una de estas dimensiones de manera individual. Esto permite comprender la naturaleza compleja y multifacética de la pobreza, lo cual a su vez posibilita diseñar estrategias de reducción efectivas. Esta aproximación garantiza una toma de decisiones fundamentada, la distribución eficiente de recursos y un impacto más profundo en la mejora de las condiciones de vida de las personas vulnerables. En este contexto, los “hard estimates” previamente obtenidos para cada dimensión resultan esenciales para obtener las estimaciones correspondientes a cada una de ellas. El proceso de cálculo se basa en una media ponderada y se aplica a la dimensión de Hacinamiento, siguiendo una lógica similar para las demás dimensiones del IPM. n_filtered &lt;- censo_ipm$n epred_mat_filtered &lt;- epred_mat_hacinamiento_dummy mrp_estimates &lt;- epred_mat_filtered %*% n_filtered / sum(n_filtered) datos &lt;- data.frame( estimate = mean(mrp_estimates), estimate_se = sd(mrp_estimates) ) Tabla 4.8: Estimaciones nacional para Hacinamiento estimate estimate_se 0.2379 0.0176 Con el objetivo de agilizar el proceso de calculo se define crea la función agregado_dim_ipm que hace los cálculos. La forma de uso es la siguiente. source(&quot;Modelo_bayes_HxA_Hogar/0funciones/agregado_dim_ipm.r&quot;) datos_dam_haci &lt;- agregado_dim_ipm(poststrat = censo_ipm, epredmat = epred_mat_hacinamiento_dummy, byMap = &quot;dam&quot;) Tabla 4.9: Estimaciones por departamento para Hacinamiento dam estimate estimate_se 05 0.1862 0.0374 08 0.4030 0.0605 11 0.1970 0.0920 13 0.3297 0.0416 15 0.1779 0.0187 17 0.1543 0.0338 18 0.1719 0.0359 19 0.2616 0.0208 20 0.3590 0.0442 23 0.3890 0.0295 25 0.2145 0.0257 27 0.2232 0.0268 41 0.1849 0.0298 44 0.4468 0.0326 47 0.3641 0.0432 50 0.1784 0.0409 52 0.3187 0.0249 54 0.2823 0.0496 63 0.1478 0.0434 66 0.1608 0.0386 68 0.1947 0.0279 70 0.3876 0.0317 73 0.1913 0.0348 76 0.1583 0.0339 81 0.2455 0.0969 85 0.2382 0.0943 86 0.2836 0.0979 88 0.2503 0.1037 91 0.5164 0.1253 94 0.4426 0.1228 95 0.2979 0.1090 97 0.5064 0.1290 99 0.3618 0.1199 El resultado por municipio y para todas las dimensiones se muestra en la siguiente tabla Tabla 4.10: Estimacion puntual por municipio y dimension dam2 nbi_hagua nbi_heducninios nbi_hempe nbi_henergia nbi_hhacina nbi_hjub nbi_hlogroeduc nbi_hnolee nbi_hpartemp nbi_hsalud nbi_hsaneamiento nbi_htic 05001 0.0011 0.0758 0.2055 0.0139 0.1904 0.1669 0.1469 0.0587 0.5199 0.0202 0.0542 0.3085 05002 0.1556 0.1482 0.5797 0.2917 0.1932 0.2395 0.4851 0.2408 0.5537 0.0162 0.2739 0.8393 05004 0.2632 0.1840 0.6590 0.4113 0.2074 0.2243 0.5749 0.2746 0.5542 0.0149 0.3529 0.8969 05021 0.1219 0.1437 0.5543 0.2471 0.1828 0.2364 0.4534 0.2295 0.5553 0.0143 0.2288 0.8203 05030 0.0767 0.1179 0.3971 0.1424 0.1913 0.2039 0.3214 0.1733 0.5576 0.0170 0.1942 0.6462 05031 0.1286 0.1581 0.5741 0.2871 0.1878 0.2094 0.4733 0.2260 0.5676 0.0155 0.2350 0.8216 05034 0.1625 0.1491 0.5061 0.2264 0.1977 0.2119 0.4048 0.2084 0.5502 0.0149 0.2704 0.7535 05036 0.1104 0.1331 0.4587 0.1817 0.1987 0.2174 0.3762 0.1968 0.5577 0.0151 0.2292 0.7359 05038 0.1863 0.1652 0.6415 0.3759 0.2017 0.2409 0.5609 0.2723 0.5689 0.0169 0.3143 0.8977 05040 0.1743 0.1721 0.6276 0.3578 0.1905 0.2146 0.5275 0.2526 0.5594 0.0173 0.2826 0.8625 Tabla 4.11: Error de estimacion por municipio y carencia dam2 nbi_hagua_se nbi_heducninios_se nbi_hempe_se nbi_henergia_se nbi_hhacina_se nbi_hjub_se nbi_hlogroeduc_se nbi_hnolee_se nbi_hpartemp_se nbi_hsalud_se nbi_hsaneamiento_se nbi_htic_se 05001 0.0081 0.0581 0.0843 0.0245 0.0884 0.0805 0.0771 0.0502 0.1129 0.0319 0.0486 0.1020 05002 0.0736 0.0672 0.0926 0.0865 0.0754 0.0826 0.0928 0.0797 0.0979 0.0248 0.0861 0.0562 05004 0.0842 0.0721 0.0823 0.0865 0.0778 0.0777 0.0919 0.0883 0.0959 0.0229 0.0952 0.0456 05021 0.0563 0.0647 0.0891 0.0668 0.0698 0.0765 0.0850 0.0742 0.0949 0.0224 0.0714 0.0666 05030 0.0457 0.0588 0.0820 0.0595 0.0674 0.0714 0.0777 0.0691 0.0879 0.0236 0.0666 0.0714 05031 0.0541 0.0635 0.0847 0.0655 0.0722 0.0709 0.0810 0.0724 0.0875 0.0221 0.0692 0.0673 05034 0.0594 0.0604 0.0814 0.0647 0.0676 0.0699 0.0793 0.0676 0.0835 0.0200 0.0752 0.0636 05036 0.0577 0.0635 0.0867 0.0670 0.0726 0.0711 0.0855 0.0724 0.0891 0.0219 0.0773 0.0633 05038 0.0904 0.0857 0.0992 0.1003 0.0867 0.0928 0.1005 0.1001 0.1026 0.0289 0.1019 0.0504 05040 0.0673 0.0677 0.0866 0.0734 0.0728 0.0762 0.0865 0.0788 0.0906 0.0235 0.0804 0.0581 "],["mapa-del-ipm-por-municipio-de-colombia.html", "Capítulo 5 Mapa del IPM por municipio de Colombia", " Capítulo 5 Mapa del IPM por municipio de Colombia Dado que los municipios son otro nivel de desagregción, es posible realizar un mapa municipal para \\(H\\), \\(A\\) e \\(IPM\\). Para realizar el proceso, previamente se guardaron las estimaciones necesarias en un archivo .rds el cual usaremos a continuación: library(sf) library(tmap) estimado_ipm &lt;- readRDS(file = &quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/estimado_ipm1.rds&quot;) temp_estimate_mpio &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/Data/Modelo/temp_estimate_mpio.rds&quot;) ShapeSAE &lt;- read_sf(&quot;Modelo_bayes_HxA_Hogar/COL/Shape/COL_dam2.shp&quot;) brks_H &lt;- round(quantile(estimado_ipm$dam2$H, probs = c(0, 0.2, 0.4, 0.6, 0.8, 1)), 2) brks_ipm &lt;- round(quantile(estimado_ipm$dam2$IPM, probs = c(0, 0.2, 0.4, 0.6, 0.8, 1)), 2) brks_A &lt;- round(quantile(estimado_ipm$dam2$A, probs = c(0, 0.2, 0.4, 0.6, 0.8, 1)), 2) maps3 &lt;- tm_shape(ShapeSAE %&gt;% left_join(estimado_ipm$dam2, by = &quot;dam2&quot;)) Para crear los mapas se usa la siguiente sintaxis thema_map &lt;- tm_layout(legend.only = FALSE, legend.height = -0.5, legend.width = -0.4, asp = 1.5, legend.text.size = 5, legend.title.size = 4) Mapa_H &lt;- maps3 + tm_polygons( &quot;H&quot;, breaks = brks_H, title = &quot;H&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + thema_map Mapa_A &lt;- maps3 + tm_polygons( &quot;A&quot;, breaks = brks_A, title = &quot;A&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + thema_map Mapa_ipm &lt;- maps3 + tm_polygons( &quot;IPM&quot;, breaks = brks_ipm, title = &quot;IPM&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + thema_map Mapas &lt;- tmap_arrange(Mapa_H, Mapa_A, Mapa_ipm) tmap_save( Mapas, &quot;Modelo_bayes_HxA_Hogar/COL/Output/COL_IPM.jpeg&quot;, width = 6920, height = 4080, asp = 0 ) "],["mapa-municipal-por-dimensión-del-ipm.html", "5.1 Mapa municipal por dimensión del IPM", " 5.1 Mapa municipal por dimensión del IPM temp_estimate_mpio &lt;- readRDS(&quot;Modelo_bayes_HxA_Hogar/COL/data/Modelo/temp_estimate_mpio.rds&quot;) brks_dim &lt;- round(quantile( temp_estimate_mpio$estimate, probs = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1) ), 2) maps2 &lt;- tm_shape(ShapeSAE %&gt;% inner_join(temp_estimate_mpio, by = &quot;dam2&quot;)) Mapa_ing2 &lt;- maps2 + tm_polygons( &quot;estimate&quot;, breaks = brks_dim, title = &quot;&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + thema_map + tm_facets(by = &quot;Indicador&quot;, ncol = 4) tmap_save( Mapa_ing2, &quot;Modelo_bayes_HxA_Hogar/COL/Output/COL_dims_ipm.jpeg&quot;, width = 6920, height = 4080, asp = 0 ) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
